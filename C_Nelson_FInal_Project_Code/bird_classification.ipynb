{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def readFromFile(file, dtype=None, cols=(0,0)):\n",
    "    f=open(file, \"r\")\n",
    "    input = f.readlines()\n",
    "    contents=[]\n",
    "    if cols==(0,0):\n",
    "        for line in input: \n",
    "            line=line[:-1]\n",
    "            contents.append(line.split(' '))\n",
    "    else:\n",
    "        for line in input: \n",
    "            line=line[:-1]\n",
    "            contents.append(line.split(' ')[cols[0]:cols[1]])\n",
    "\n",
    "    if dtype!=None:\n",
    "        contents = np.array(contents).astype(dtype)\n",
    "    else:\n",
    "        contents = np.array(contents)\n",
    "    return contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   1   1 ... 200 200 200]\n"
     ]
    }
   ],
   "source": [
    "truth = readFromFile(\"./CUB_200_2011/image_class_labels.txt\", 'int16', (1,2))\n",
    "truth = truth.reshape((1,11788))\n",
    "truth = truth[0]\n",
    "print(truth)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    1     1     0]\n",
      " [    1     2     0]\n",
      " [    1     3     0]\n",
      " ...\n",
      " [11788   310     0]\n",
      " [11788   311     0]\n",
      " [11788   312     1]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filenames = readFromFile(\"./CUB_200_2011/images.txt\",None,(1,2))\n",
    "class_nms = readFromFile(\"./CUB_200_2011/classes.txt\")\n",
    "train_idxs = readFromFile(\"./CUB_200_2011/train_test_split.txt\", 'int16',(1,2))\n",
    "importance = readFromFile(\"./CUB_200_2011/attributes/class_attribute_labels_continuous.txt\", 'float')\n",
    "attributes = readFromFile(\"./CUB_200_2011/attributes/image_attribute_labels.txt\", 'int16', (0,3))\n",
    "attribs = np.empty([11788, 312], dtype='int16')\n",
    "for line in attributes:\n",
    "    attribs[line[0]-1][line[1]-1] = line[2]\n",
    "# print(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11788, 312)\n",
      "[ -1 171  -1 ... 200 174 200]\n",
      "0.04691211401425178\n",
      "1055\n",
      "(11788, 312)\n",
      "[ -1 179  46 ... 182 130 198]\n",
      "0.047675602307431286\n",
      "1823\n",
      "(11788, 312)\n",
      "[ -1  32  -1 ...  12  27 200]\n",
      "0.035374957583983714\n",
      "3936\n",
      "(11788, 312)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-0edc7e7ebe41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtrue_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mbird\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                     \u001b[0mtrue_total\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrue_total\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "r1 = random.randint(3, 10) \n",
    "imps = np.copy(importance)\n",
    "y = 0\n",
    "# topXfeatures = [[None for _ in range(x)] for _ in range(200)]\n",
    "x=10\n",
    "topXfeatures = np.empty((200,x), dtype='int')\n",
    "\n",
    "\n",
    "\n",
    "for row in imps: \n",
    "    for j in range(x):\n",
    "        max_index = np.argmax(row)\n",
    "        topXfeatures[y,j] = max_index\n",
    "        row[max_index]=0\n",
    "#         print(max_index, end = ' ')\n",
    "#     print()\n",
    "    y+=1\n",
    "\n",
    "\n",
    "# topXfeatures[0][2] = 5   \n",
    "# print(topXfeatures)\n",
    "# print(topXfeatures.shape)\n",
    "\n",
    "output = np.full(11788,-1)\n",
    "n=0\n",
    "#     print(attribs.shape)\n",
    "for bird in attribs:\n",
    "    m=1\n",
    "    for row in topXfeatures:\n",
    "        true_total = 0\n",
    "        for index in row:\n",
    "            if bird[index]==1:\n",
    "                true_total+=1\n",
    "        if true_total>x-4:\n",
    "            output[n] = m\n",
    "        m+=1\n",
    "    n+=1\n",
    "\n",
    "print(output)\n",
    "\n",
    "\n",
    "correct = 0\n",
    "negones = 0\n",
    "TOTAL = 11788\n",
    "for i in range(output.shape[0]):\n",
    "    if output[i]==truth[i]:\n",
    "        correct+=1\n",
    "    elif output[i]==-1:\n",
    "        negones+=1\n",
    "print(correct/TOTAL)\n",
    "print(negones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017984390906006106\n",
      "2987\n"
     ]
    }
   ],
   "source": [
    "np.random.randint(200, size=11788)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.21428571 0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.10687023 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.10687023 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.29770992]]\n",
      "(11788, 312)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# print(attribs)\n",
    "# for row in attribs:\n",
    "# print(importance)\n",
    "# attributes = np.multiply()\n",
    "attributes = []\n",
    "for i in range(11788):\n",
    "    attributes.append(np.multiply(attribs[i],importance[truth[i]-1]))\n",
    "    pass\n",
    "#     if train_idxs[i][0] == 1:\n",
    "        \n",
    "#     else:\n",
    "#         attributes.append(attribs[i])\n",
    "attributes = np.asarray(attributes)/100\n",
    "# attributes = np.append(attributes, np.ones((11788,1)))\n",
    "# attributes.shape = (11788, 313)\n",
    "# attributes = attributes + np.ones((11788, 1))\n",
    "# print(attributes)\n",
    "# print(attributes.shape)\n",
    "    #multiplys attribute row with importance of \n",
    "# def computeLinear():\n",
    "#     global W\n",
    "#     W = np.dot(np.linalg.inv(np.dot(np.transpose(attribs), attribs)), np.dot(np.transpose(attribs),truth))\n",
    "#     pred_rates = np.dot(attribs, np.transpose(W))\n",
    "#     N = truth.size\n",
    "#     rmse = np.sqrt(np.sum(np.square(pred_rates-truth))/N)\n",
    "#     return rmse\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8008008008008008\n",
      "0.7026234035208837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisnelson/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.012081463583016915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisnelson/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/chrisnelson/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9002335669002336\n",
      "0.7823610631687953\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "atr_train = []\n",
    "atr_test = []\n",
    "truth_train = []\n",
    "truth_test = []\n",
    "for i in range(11788):\n",
    "    if train_idxs[i][0] == 1:\n",
    "        atr_train.append(attributes[i])\n",
    "        truth_train.append(truth[i])\n",
    "    else:\n",
    "        atr_test.append(attributes[i])\n",
    "        truth_test.append(truth[i])\n",
    "        \n",
    "atr_train = np.asarray(atr_train)\n",
    "atr_test = np.asarray(atr_test)\n",
    "truth_train = np.asarray(truth_train)\n",
    "truth_test = np.asarray(truth_test)\n",
    "    \n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "lda.fit(atr_train, truth_train)\n",
    "lda_score_train = lda.score(atr_train, truth_train)\n",
    "lda_score_test = lda.score(atr_test, truth_test)\n",
    "\n",
    "print(lda_score_train)\n",
    "print(lda_score_test)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "qda.fit(atr_train, truth_train)\n",
    "qda_score_train = qda.score(atr_train, truth_train)\n",
    "qda_score_test = qda.score(atr_test, truth_test)\n",
    "print(qda_score_train)\n",
    "print(qda_score_test)\n",
    "randarr = np.random.randint(2, size=truth_test.shape[0])\n",
    "\n",
    "log = LogisticRegression(random_state=0).fit(atr_train, truth_train)\n",
    "log_score_train = log.score(atr_train, truth_train)\n",
    "log_score_test = log.score(atr_test, truth_test)\n",
    "\n",
    "print(log_score_train)\n",
    "print(log_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9216430790472903\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(atr_train, truth_train)\n",
    "dt_score_train = dt.score(atr_train, truth_train)\n",
    "dt_score_test = dt.score(atr_test, truth_test)\n",
    "print(dt_score_train)\n",
    "print(dt_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66332999666333\n",
      "0.6051087331722471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(gamma='auto')\n",
    "svm.fit(atr_train, truth_train)\n",
    "SVC(gamma='auto')\n",
    "print(svm.score(atr_train, truth_train))\n",
    "print(svm.score(atr_test, truth_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12982618 0.10220634 0.07062515 0.05359489]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "# x = StandardScaler().fit_transform(atr_train)\n",
    "principalComponents = pca.fit_transform(atr_train)\n",
    "# principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KMeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fd8b0ce2c3b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KMeans' is not defined"
     ]
    }
   ],
   "source": [
    "km = KMeans(200)\n",
    "km.fit(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(truth_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_path = \"./CUB_200_2011/images/\"\n",
    "images = []\n",
    "print(\"hello\")\n",
    "\n",
    "for i in range(10):# in filenames:\n",
    "    images.append(cv2.imread(init_path+filenames[i][1]))\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"hello\")\n",
    "images = np.asarray(images)\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.empty([3, 2], dtype='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
